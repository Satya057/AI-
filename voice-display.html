<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéß Voice Assistant</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0;
            padding: 21px;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 600px;
            width: 100%;
        }
        
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        
        .status {
            text-align: center;
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 10px;
            background: #f8f9fa;
        }
        
        .mic-button {
            width: 180px;
            height: 60px;
            border-radius: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            color: white;
            font-size: 18px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 30px auto;
            display: block;
            box-shadow: 0 8px 20px rgba(0,0,0,0.2);
        }
        
        .mic-button:hover {
            background: linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%);
            transform: translateY(-2px);
            box-shadow: 0 12px 25px rgba(0,0,0,0.3);
        }
        
        .mic-button.listening {
            background: linear-gradient(135deg, #ffc107 0%, #ff9800 100%);
            color: #333;
        }
        
        .mic-button:active {
            transform: translateY(0);
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        
        .question-section, .answer-section {
            margin: 20px 0;
            padding: 20px;
            border-radius: 15px;
            border-left: 5px solid #667eea;
        }
        
        .question-section {
            background: #e3f2fd;
        }
        
        .answer-section {
            background: #f3e5f5;
        }
        
        .label {
            font-weight: bold;
            color: #333;
            margin-bottom: 10px;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
            color: #555;
        }
        
        .timestamp {
            font-size: 12px;
            color: #888;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üéß Voice Assistant</h1>
            <p>Ask a question, and get a simple answer in 10 lines.</p>
        </div>
        
        <div class="status">
            <span id="status-text">üé§ Click microphone to start</span>
        </div>
        
        <div class="question-section">
            <div class="label">üé§ Question:</div>
            <div class="content" id="current-question">Ask any question...</div>
            <div class="timestamp" id="question-time"></div>
        </div>
        
        <div class="answer-section">
            <div class="label">üß† Answer:</div>
            <div class="content" id="current-answer">The answer will be shown here...</div>
            <div class="timestamp" id="answer-time"></div>
        </div>
    </div>

    <button class="mic-button" id="mic-button" onclick="toggleListening()">üé§ Interview Mode</button>

    <script>
        let isListening = false;
        let isProcessing = false;
        let recognition;
        let conversationHistory = [];
        
        // Load conversation history from localStorage
        function loadConversationHistory() {
            const saved = localStorage.getItem('voiceAssistantHistory');
            if (saved) {
                conversationHistory = JSON.parse(saved);
                console.log('üìö Loaded conversation history:', conversationHistory.length, 'items');
            }
        }
        
        // Save conversation history to localStorage
        function saveConversationHistory() {
            localStorage.setItem('voiceAssistantHistory', JSON.stringify(conversationHistory));
            console.log('üíæ Saved conversation history');
        }
        
        // Add new conversation to history
        function addToHistory(question, answer) {
            const conversation = {
                question: question,
                answer: answer,
                timestamp: new Date().toLocaleString()
            };
            conversationHistory.push(conversation);
            
            // Keep only last 20 conversations
            if (conversationHistory.length > 20) {
                conversationHistory = conversationHistory.slice(-20);
            }
            
            saveConversationHistory();
        }
        
        // Load history when page loads
        loadConversationHistory();
        
        // Initialize speech recognition
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US'; // English language support
            recognition.maxAlternatives = 3; // Get multiple alternatives
            
            recognition.onstart = function() {
                console.log('üé§ Speech recognition started');
                updateStatus('üé§ Listening... Click button to stop.');
                document.getElementById('mic-button').classList.add('listening');
            };
            
            recognition.onresult = function(event) {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Show interim results in real-time
                if (interimTranscript) {
                    document.getElementById('current-question').textContent = interimTranscript;
                }
                
                if (finalTranscript) {
                    console.log('üé§ Heard:', finalTranscript);
                    updateQuestion(finalTranscript);
                    processQuestion(finalTranscript);
                }
            };
            
            recognition.onaudiostart = function() {
                console.log('üé§ Audio capturing started');
            };
            
            recognition.onaudioend = function() {
                console.log('üé§ Audio capturing ended');
            };
            
            recognition.onsoundstart = function() {
                console.log('üé§ Sound detected');
            };
            
            recognition.onsoundend = function() {
                console.log('üé§ Sound ended');
            };
            
            recognition.onspeechstart = function() {
                console.log('üé§ Speech started');
            };
            
            recognition.onspeechend = function() {
                console.log('üé§ Speech ended');
            };
            
            recognition.onerror = function(event) {
                console.error('‚ùå Speech recognition error:', event.error);
                updateStatus('‚ùå Error: ' + event.error);
                document.getElementById('mic-button').classList.remove('listening');
                
                // Try to restart if it's a network error
                if (event.error === 'network' && isListening) {
                    setTimeout(() => {
                        if (isListening) {
                            console.log('üîÑ Retrying speech recognition...');
                            recognition.start();
                        }
                    }, 1000);
                }
            };
            
            recognition.onend = function() {
                console.log('üé§ Speech recognition ended');
                isListening = false;
                document.getElementById('mic-button').classList.remove('listening');
                if (!isProcessing) {
                    updateStatus('üé§ Click "Interview Mode" to start');
                }
            };
        } else {
            updateStatus('‚ùå Speech recognition not supported');
        }
        
        function toggleListening() {
            if (!recognition) {
                alert('Speech recognition not supported in this browser');
                return;
            }

            if (isProcessing) {
                console.log('Still processing previous question.');
                return;
            }
            
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }
        
        function startListening() {
            isListening = true;
            recognition.start();
        }
        
        function stopListening() {
            isListening = false;
            recognition.stop();
        }
        
        function updateQuestion(question) {
            document.getElementById('current-question').textContent = question;
            document.getElementById('question-time').textContent = new Date().toLocaleTimeString();
        }
        
        function updateAnswer(answer) {
            document.getElementById('current-answer').textContent = answer;
            document.getElementById('answer-time').textContent = new Date().toLocaleTimeString();
        }
        
        function updateStatus(status) {
            document.getElementById('status-text').textContent = status;
        }
        
        async function processQuestion(question) {
            updateStatus('üß† Getting an answer from the AI...');
            isProcessing = true;
            
            try {
                const response = await fetch('/process-question', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ 
                        question: question,
                        conversationHistory: conversationHistory.slice(-3) // Send last 3 conversations for context
                    })
                });
                
                const data = await response.json();
                const answer = data.answer;
                
                updateAnswer(answer);
                addToHistory(question, answer); // Add to conversation history
                updateStatus('üé§ Ready. Click "Interview Mode" to ask a new question.');
                
            } catch (error) {
                console.error('‚ùå Error processing question:', error);
                updateAnswer('Sorry, I could not process your question.');
                updateStatus('‚ùå Error. Click "Interview Mode" to try again.');
            } finally {
                isProcessing = false;
            }
        }
    </script>
</body>
</html>